mdp
const int N=4;
const int M=12;
const double p=0.21; // with probability p, a move to a neighboring state state occurs due to seeing and control noise
formula wall = (r=4 & c=2) | (r=4 & c=3) | (r=4 & c=4) | (r=4 & c=5) | (r=4 & c=6) | (r=4 & c=7) | (r=4 & c=8) | (r=4 & c=9) | (r=4 & c=10) | (r=4 & c=11);

module robot
	//define robot position
	r:[1..N] init 4; //grid row
	c:[1..M] init 1; //grid column

	// transitions
	[east]  (c<M | c=M) -> p/3:(r'=min(r+1, N))+ p/3: (c'=max(c-1, 1))+ p/3: (r'=max(r-1, 1)) + (1-p): (c'=min(c+1, M));
	[south] (r<N | r=N) -> (1-p):(r'=min(r+1, N)) + p/3: (c'=min(c+1, M)) + p/3:(r'=max(r-1, 1))+ p/3: (c'=max(c-1, 1));
	[west]  (c>1 | c=1) -> p/3:(r'=max(r-1, 1))+ p/3:(r'=min(r+1, N))+ p/3: (c'=min(c+1, M)) + (1-p): (c'=max(c-1, 1));
	[north] (r=1 | r>1) -> (1-p):(r'=max(r-1, 1)) + p/3: (c'=max(c-1, 1)) + p/3: (c'=min(c+1, M)) + p/3:(r'=min(r+1, N));

	// terminal state self-loop to avoid deadlock
	[] r=4 & c=12 -> true;

endmodule

label "goal" = r=4 & c=12;

label "obs" = (r=4 & c=2) | (r=4 & c=3) | (r=4 & c=4) | (r=4 & c=5) | (r=4 & c=6) | (r=4 & c=7) | (r=4 & c=8) | (r=4 & c=9) | (r=4 & c=10) | (r=4 & c=11);

rewards
	[east] !wall : 1;
	[south] !wall : 1;
	[west] !wall : 1;
	[north] !wall : 1;

	[east] wall : 35;
    [south] wall : 35;
    [west] wall : 35;
    [north] wall : 35;

endrewards
