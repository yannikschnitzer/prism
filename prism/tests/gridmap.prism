mdp

const int N = 5;  // N*N grid map
const double p = 0.1; // with probability p, a move to a neighboring state state occurs due to seeing and control noise


module robot
	
	// define robot position
	r:[1..N] init 1;  // grid row
	c:[1..N] init 1;  // grid column

	// go to the terminal state when hitting an obstacle 
	// here obstacle states are (2,2), (2,4), which can be generated randomly using Python code
	[obstacle] (r=2 & c=2) | (r=2 & c=4) -> (r'=N) & (c'=N); 

	// at each time step the agent can move to any of its four neighboring states, except in the obstacle or terminal states
	// actions along the grid borders are limited
	[east] r<N & c<N & !((r=2 & c=2) | (r=2 & c=4) | (r=N & c=N)) -> p:(r'=r+1) + (1-p): (c'=c+1);
	[south] r<N & c<N & !((r=2 & c=2) | (r=2 & c=4) | (r=N & c=N)) -> (1-p):(r'=r+1) + p: (c'=c+1);
	[west] r>1 & c>1 & !((r=2 & c=2) | (r=2 & c=4) | (r=N & c=N)) -> p:(r'=r-1) + (1-p): (c'=c-1);
	[north] r>1 & c>1 & !((r=2 & c=2) | (r=2 & c=4) | (r=N & c=N)) -> (1-p):(r'=r-1) + p: (c'=c-1);

	// corner cases
	[east] r=N & c=1  -> p:(r'=r-1) + (1-p): (c'=c+1);
	[south] r=1 & c=N -> (1-p):(r'=r+1) + p: (c'=c-1);
	[west] r=1 & c=N  -> p:(r'=r+1) + (1-p): (c'=c-1);
	[north] r=N & c=1 -> (1-p):(r'=r-1) + p: (c'=c+1);

	// terminal state self-loop to avoid deadlock
	[] r=N & c=N -> true;

endmodule 

label "goal" = r=N & c=N; 

rewards
	[east] true : 1;
	[south] true: 1;
	[west] true: 1;
	[north] true: 1;
	[obstacle] true: 50;
endrewards







