mdp
const int N=4;
const int M=12;
const double p=0.15; // with probability p, a move to a neighboring state state occurs due to seeing and control noise

module robot
	//define robot position
	r:[1..N] init 4; //grid row
	c:[1..M] init 1; //grid column

	// go to the terminal state when hitting an obstacle
	[obstacle] (r=4 & c=2) | (r=4 & c=3) | (r=4 & c=4) | (r=4 & c=5) | (r=4 & c=6) | (r=4 & c=7) | (r=4 & c=8) | (r=4 & c=9) | (r=4 & c=10) | (r=4 & c=11)-> (r'=4) & (c'=12);

	// transitions
	[east] (c<M | c=M) & !((r=4 & c=2) | (r=4 & c=3) | (r=4 & c=4) | (r=4 & c=5) | (r=4 & c=6) | (r=4 & c=7) | (r=4 & c=8) | (r=4 & c=9) | (r=4 & c=10) | (r=4 & c=11))-> p/3:(r'=min(r+1, N))+ p/3: (c'=max(c-1, 1))+ p/3: (r'=max(r-1, 1)) + (1-p): (c'=min(c+1, M));
	[south] (r<N | r=N) & !((r=4 & c=2) | (r=4 & c=3) | (r=4 & c=4) | (r=4 & c=5) | (r=4 & c=6) | (r=4 & c=7) | (r=4 & c=8) | (r=4 & c=9) | (r=4 & c=10) | (r=4 & c=11))-> (1-p):(r'=min(r+1, N)) + p/3: (c'=min(c+1, M)) + p/3:(r'=min(r+1, N))+ p/3: (c'=max(c-1, 1));
	[west]  (c>1 | c=1) & !((r=4 & c=2) | (r=4 & c=3) | (r=4 & c=4) | (r=4 & c=5) | (r=4 & c=6) | (r=4 & c=7) | (r=4 & c=8) | (r=4 & c=9) | (r=4 & c=10) | (r=4 & c=11))-> p/3:(r'=max(r-1, 1))+ p/3:(r'=min(r+1, N))+ p/3: (c'=min(c+1, M)) + (1-p): (c'=max(c-1, 1));
	[north] (r=1 | r>1) & !((r=4 & c=2) | (r=4 & c=3) | (r=4 & c=4) | (r=4 & c=5) | (r=4 & c=6) | (r=4 & c=7) | (r=4 & c=8) | (r=4 & c=9) | (r=4 & c=10) | (r=4 & c=11))-> (1-p):(r'=max(r-1, 1)) + p/3: (c'=max(c-1, 1)) + p/3: (c'=min(c+1, M)) + p/3:(r'=min(r+1, N));

	// terminal state self-loop to avoid deadlock
	[] r=4 & c=12 -> true;
endmodule

label "goal" = r=4 & c=12;

label "obs" = (r=4 & c=2) | (r=4 & c=3) | (r=4 & c=4) | (r=4 & c=5) | (r=4 & c=6) | (r=4 & c=7) | (r=4 & c=8) | (r=4 & c=9) | (r=4 & c=10) | (r=4 & c=11);

rewards
	[east] true : 1;
	[south] true : 1;
	[west] true : 1;
	[north] true : 1;
	[obstacle] true : 35;
endrewards
