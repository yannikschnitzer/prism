package explicit;

import java.util.Iterator;
import java.util.Map;
import java.util.TreeMap;

abstract class DistributionalBellman {

    int atoms = 1;
    int nactions = 4;
    double v_min ;
    double v_max ;
    double alpha=1;

    public DistributionalBellman(){}

    public void setAlpha(double a){ alpha=a;}

    // Distributional Bellman update using transitions probabilities, discount factor <gamma> and reward <state_reward>
    // This function also performs projection for the distributional operators.
    public abstract double [] step(Iterator<Map.Entry<Integer, Double>> trans_it, int numTransitions, double gamma, double state_reward);

    // Get Expected value of a distribution <probs> with an alpha = <lim>
    public abstract double getExpValue(double [] temp);

    // Get Conditional Value at Risk value of a distribution <probs> with an alpha = <lim> , assumes same support
    public abstract double getValueCvar(double [] probs, double lim);

    // Get Value at risk of a distribution <probs> with an alpha = <lim> , assumes same support
    public abstract double getVar(double [] probs, double lim);

    // Get Variance of a distribution <probs>, assumes same support
    public abstract double getVariance(double [] probs);

    // Get distributional distance between two distributions <dist1> and <dist2>, assumes same support
    public abstract double getW(double[] dist1, double[] dist2);

    // Get distributional distance between a distribution <dist1> and the distribution for a state <state>
    // assumes same support
    public abstract double getW(double[] dist1, int state);

    // Initializes opterator with n = number of non infinite states
    public abstract void initialize(int n);

    // update the saved distribution with temp for a given state, assumes same support
    public abstract void update(double [] temp, int state);

    // Retrieve distribution for a state i
    public abstract double[] getDist(int i);

    // Converts a distribution generated by : DTMCModelChecker.computeReachRewardsDistr()
    // to an approximate distribution (limited supports)
    public abstract double [] adjust_support(TreeMap distr);

    // Log distribution for a state to a file <filename> as a csv with columns : support index, probability, support value
    public abstract void writeToFile(int state, String filename);
//    public abstract double [][] getDist();
}
